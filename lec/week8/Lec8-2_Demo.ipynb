{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "VV1IvM285zvR",
   "metadata": {
    "id": "VV1IvM285zvR"
   },
   "source": [
    "# Text Pre-Processinf and Feature Engineering\n",
    "\n",
    "In this notebook, we will explore several methods of text classification and feature extraction, focusing on various techniques and their practical applications. Topics covered include:\n",
    "\n",
    "- **Vector Space Representation**\n",
    "- **Feature Engineering**\n",
    "- **Text Pre-processing**\n",
    "  - Tokenization Issues\n",
    "  - Stop Words & Normalization\n",
    "  - Lemmatization & Stemming\n",
    "- **Real World Issues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aPdtDHu5-xN",
   "metadata": {
    "id": "4aPdtDHu5-xN"
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cEiVOmH15zvU",
   "metadata": {
    "id": "cEiVOmH15zvU"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ju6FcDMkGzO",
   "metadata": {
    "id": "1ju6FcDMkGzO"
   },
   "outputs": [],
   "source": [
    "# Download necessary NLTK resources\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ta6bmunp5zvW",
   "metadata": {
    "id": "Ta6bmunp5zvW"
   },
   "source": [
    "## Vector Space Representation\n",
    "\n",
    "Text classification can be viewed as a vector space model where documents are represented as vectors in a multi-dimensional space. Each dimension corresponds to a term in the document corpus. We will explore **CountVectorizer** and **TF-IDF** as methods for feature extraction in text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X2WY1PIILFtS",
   "metadata": {
    "id": "X2WY1PIILFtS"
   },
   "source": [
    "### Sample text documents for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KOq_fialK8b8",
   "metadata": {
    "id": "KOq_fialK8b8"
   },
   "outputs": [],
   "source": [
    "# Sample text documents for demonstration\n",
    "documents = [\n",
    "    \"Data Mining involves discovering patterns in large datasets to extract useful knowledge.\",\n",
    "    \"Data Science is a multidisciplinary field that uses scientific methods to extract knowledge from structured and unstructured data.\",\n",
    "    \"Machine Learning is a subset of Artificial Intelligence that enables systems to learn from data and improve without explicit programming.\",\n",
    "    \"Artificial Intelligence refers to the simulation of human intelligence in machines that are programmed to think and learn.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-0L5OrhALHmD",
   "metadata": {
    "id": "-0L5OrhALHmD"
   },
   "source": [
    "### Increse similarity between documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ALzkFi40LK5p",
   "metadata": {
    "id": "ALzkFi40LK5p"
   },
   "outputs": [],
   "source": [
    "# Increse similarity between documents\n",
    "documents = [\n",
    "    \"Data Mining involves discovering patterns in large datasets, applying scientific methods to extract useful knowledge and insights from both structured and unstructured data.\",\n",
    "    \"Data Science is a multidisciplinary field that uses scientific methods, algorithms, and systems to extract knowledge and insights from both structured and unstructured data, similar to Data Mining.\",\n",
    "    \"Machine Learning, a subset of Artificial Intelligence, uses algorithms and statistical models to learn from data and improve predictions or decisions without explicit programming, closely related to Data Mining and Data Science.\",\n",
    "    \"Artificial Intelligence encompasses systems that simulate human intelligence, including machine learning algorithms that learn from data to improve performance, making it closely related to Data Mining, Data Science, and Machine Learning.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XXqE3K9WLBeQ",
   "metadata": {
    "id": "XXqE3K9WLBeQ"
   },
   "source": [
    "### Use CountVectorizer to transform text into feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZdxghZ9yK_tN",
   "metadata": {
    "id": "ZdxghZ9yK_tN"
   },
   "outputs": [],
   "source": [
    "# Use CountVectorizer to transform text into feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Display the feature vectors\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JQETN6Xu5zvZ",
   "metadata": {
    "id": "JQETN6Xu5zvZ"
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature engineering is a crucial step in text classification. The raw text data must be transformed into numerical features that machine learning models can process. We will explore methods like tokenization, removing stop words, and normalization of terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-2HyaV_95zvZ",
   "metadata": {
    "id": "-2HyaV_95zvZ"
   },
   "outputs": [],
   "source": [
    "# Tokenization and Stop Words Removal\n",
    "nltk.download('all')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove punctuation and stop words\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iqE3a7gfiRI-",
   "metadata": {
    "id": "iqE3a7gfiRI-"
   },
   "outputs": [],
   "source": [
    "# Preprocess the documents\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "preprocessed_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O-mz7JCE5zvb",
   "metadata": {
    "id": "O-mz7JCE5zvb"
   },
   "source": [
    "## Lemmatization and Stemming\n",
    "\n",
    "Lemmatization and stemming are techniques for reducing words to their base or root form. Stemming often removes prefixes and suffixes, while lemmatization maps a word to its dictionary form.\n",
    "We will demonstrate both techniques using the `PorterStemmer` and `WordNetLemmatizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CH2AdR6c5zvb",
   "metadata": {
    "id": "CH2AdR6c5zvb"
   },
   "outputs": [],
   "source": [
    "# Lemmatization and Stemming Example\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def lemmatize_and_stem(tokens):\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    stemmed = [stemmer.stem(word) for word in tokens]\n",
    "    return lemmatized, stemmed\n",
    "\n",
    "# Apply lemmatization and stemming\n",
    "lemmatized_documents, stemmed_documents = zip(*[lemmatize_and_stem(doc) for doc in preprocessed_documents])\n",
    "lemmatized_documents, stemmed_documents"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dmsp26",
   "language": "python",
   "name": "dmsp26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
